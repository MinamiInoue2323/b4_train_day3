{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinamiInoue2323/b4_train_day3/blob/main/BERT%E4%BA%8B%E5%89%8D%E5%AD%A6%E7%BF%92%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E4%BD%BF%E3%81%A3%E3%81%A6%E3%81%BF%E3%82%88%E3%81%86.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FSzu7rDsQyK"
      },
      "source": [
        "参考参考\n",
        "https://note.com/npaka/n/n5bb043191cc9\n",
        "https://qiita.com/karaage0703/items/30485c2ba1c396760982"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv299lFiq3wk"
      },
      "source": [
        "# 環境構築"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivbmXx_fq12X"
      },
      "outputs": [],
      "source": [
        "#必要なライブラリのセットアップ\n",
        "!pip install transformers\n",
        "!pip install pandas\n",
        "!pip install ipadic\n",
        "!pip install fugashi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfnbZjZnyW1L"
      },
      "outputs": [],
      "source": [
        "#MeCabのインストール\n",
        "!apt install aptitude\n",
        "!aptitude install mecab libmecab-dev mecab-ipadic-utf8 git make curl xz-utils file -y\n",
        "!pip install mecab-python3==0.7\n",
        "!pip install fugashi ipadic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ドライブをcolaboratoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('content/drive')"
      ],
      "metadata": {
        "id": "moxBr3M9r2cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYtxt9QTyquM"
      },
      "outputs": [],
      "source": [
        "#ライブラリが正しくインストールされているか確認、エラーが出なければエラーが出なければok\n",
        "import torch\n",
        "import MeCab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8W3JRVL8H_k"
      },
      "source": [
        "# マスク予測をやってみる"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 下準備"
      ],
      "metadata": {
        "id": "GjdnUMFYu3wI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUZ1enRF8Hqk"
      },
      "outputs": [],
      "source": [
        "#対象となる文章\n",
        "sentence = '私は明日の午後近所の海鮮丼屋で[MASK]を食べる予定だ。'\n",
        "input_sentence = '[CLS]{}[SEP]'.format(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxqfC4Ds8jET"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForMaskedLM, BertConfig\n",
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, pipeline, BertForMaskedLM, BertConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "och-dXdP8uWb"
      },
      "outputs": [],
      "source": [
        "model_name = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
        "\n",
        "#modelの設定の定義\n",
        "config = BertConfig.from_pretrained( model_name, output_hidden_states=True)\n",
        "\n",
        "#tokenizerの読み込みと保存\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)\n",
        "tokenizer.save_pretrained(\"./tokenizer\")\n",
        "#tokenizerが正常に動くか確認\n",
        "tokenizer.tokenize('お腹が痛いので遅れます。')\n",
        "\n",
        "#モデルの読み込みと保存\n",
        "model = BertForMaskedLM.from_pretrained(model_name, config = config)\n",
        "model.save_pretrained('./model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j057zgTe_wIR"
      },
      "source": [
        "## 方法1:tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJHuFKCV_vqK"
      },
      "outputs": [],
      "source": [
        "##BERT入力前の下準備\n",
        "#入力文をトークンに分割\n",
        "tokenized_input = tokenizer.tokenize(input_sentence)\n",
        "print(tokenized_input)\n",
        "\n",
        "#トークン化された文章を文章をBERTに入力できる形に変換\n",
        "id_input = tokenizer.convert_tokens_to_ids(tokenized_input)\n",
        "print(id_input)\n",
        "tensor_input = torch.tensor([id_input])\n",
        "print(tensor_input)\n",
        "\n",
        "#[MASK]のトークンのidを取得\n",
        "mask_token_index = torch.where(tensor_input == tokenizer.mask_token_id)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noiubIz3Eo5N"
      },
      "outputs": [],
      "source": [
        "show_top = 5 #予測の上位何件を表示するか\n",
        "with torch.no_grad():\n",
        "  token_logits = model(tensor_input).logits\n",
        "  mask_token_logits = token_logits[0, mask_token_index, :]\n",
        "  top_tokens = torch.topk(mask_token_logits, show_top, dim=1).indices[0].tolist()\n",
        "  top_values = torch.topk(mask_token_logits, show_top, dim=1).values[0].tolist()\n",
        "for i in range(show_top):\n",
        "  token = tokenizer.decode(top_tokens[i])\n",
        "  value = top_values[i]\n",
        "  print('token: {}, confidence: {}'.format(token, value))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzX5hlT5_RjX"
      },
      "source": [
        "## 方法2:pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cdv7EPlC9dYw"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "#パイプラインの作成\n",
        "nlp = pipeline('fill-mask', model = model, tokenizer = tokenizer)\n",
        "\n",
        "#mask predictionの実行\n",
        "result = nlp(input_sentence)\n",
        "\n",
        "#結果の出力\n",
        "for r in result:\n",
        "  print(r)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "BERT事前学習モデルを使ってみよう.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPpQNFrndD71aVEjEtp304j",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}